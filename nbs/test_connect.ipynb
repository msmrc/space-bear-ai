{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.get_data import get_user, get_project, get_all_projects, get_all_users\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "embedds_file = open('/Users/andrey.krotkikh/Downloads/wiki.ru.vec', 'r')\n",
    "lines = embedds_file.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "1888424"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open('../assets/embedds.pickle', 'rb') as f:\n",
    "    embeddings_dict = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame.from_dict(embeddings_dict).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parquet must have string column names",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43membeddings_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43membedds.parquet\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/spacebear/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[0;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/spacebear/lib/python3.8/site-packages/pandas/core/frame.py:2974\u001B[0m, in \u001B[0;36mDataFrame.to_parquet\u001B[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001B[0m\n\u001B[1;32m   2887\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2888\u001B[0m \u001B[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001B[39;00m\n\u001B[1;32m   2889\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2970\u001B[0m \u001B[38;5;124;03m>>> content = f.read()\u001B[39;00m\n\u001B[1;32m   2971\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2972\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparquet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_parquet\n\u001B[0;32m-> 2974\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_parquet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2975\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpartition_cols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartition_cols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2982\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2983\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/spacebear/lib/python3.8/site-packages/pandas/io/parquet.py:430\u001B[0m, in \u001B[0;36mto_parquet\u001B[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m impl \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[1;32m    428\u001B[0m path_or_buf: FilePath \u001B[38;5;241m|\u001B[39m WriteBuffer[\u001B[38;5;28mbytes\u001B[39m] \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mBytesIO() \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m path\n\u001B[0;32m--> 430\u001B[0m \u001B[43mimpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpartition_cols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpartition_cols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, io\u001B[38;5;241m.\u001B[39mBytesIO)\n",
      "File \u001B[0;32m~/spacebear/lib/python3.8/site-packages/pandas/io/parquet.py:168\u001B[0m, in \u001B[0;36mPyArrowImpl.write\u001B[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrite\u001B[39m(\n\u001B[1;32m    159\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    160\u001B[0m     df: DataFrame,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    167\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 168\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m     from_pandas_kwargs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mschema\u001B[39m\u001B[38;5;124m\"\u001B[39m: kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mschema\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)}\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/spacebear/lib/python3.8/site-packages/pandas/io/parquet.py:130\u001B[0m, in \u001B[0;36mBaseImpl.validate_dataframe\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39minferred_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstring\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mempty\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m--> 130\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparquet must have string column names\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;66;03m# index level names must be strings\u001B[39;00m\n\u001B[1;32m    133\u001B[0m valid_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mall\u001B[39m(\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(name, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mnames \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    135\u001B[0m )\n",
      "\u001B[0;31mValueError\u001B[0m: parquet must have string column names"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "embeddings_df.columns = [str(x) for x in embeddings_df.columns.tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "embeddings_df.to_parquet('embedds.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_parquet = pd.read_parquet('embedds.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.02952424,  0.03973465,  0.51920575,  0.2742361 , -0.56496364,\n       -0.05899953,  0.15973805,  0.36940977, -0.28356385,  0.0317634 ,\n        0.0545611 , -0.4064595 , -0.30602503,  0.1400957 , -0.42900386,\n       -0.26042384, -0.35757917,  0.2937732 ,  0.6116437 , -0.30295795,\n        0.02860113, -0.09477986,  0.12079441,  0.5180067 , -0.20671937,\n       -0.1374913 , -0.19656545,  0.11080171,  0.00718931, -0.26903504,\n        0.16081983, -0.15745698,  0.16667393, -0.38068062, -0.07165289,\n        0.09804589,  0.06312373, -0.15158296,  0.19063157,  0.6958586 ,\n        0.03368482,  0.130759  ,  0.17316923, -0.32077733, -0.0483497 ,\n        0.23173176, -0.32908714, -0.07346074, -0.39619485,  0.19769314],\n      dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parquet.loc['В'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "chunk_size = int(test_parquet.shape[0] / 40)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    selected_df = test_parquet.iloc[i * chunk_size : (i + 1) * chunk_size]\n",
    "    selected_df.to_parquet(f\"chunk_{i}.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}